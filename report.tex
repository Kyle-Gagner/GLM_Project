\documentclass[letterpaper,titlepage,10pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage[letterpaper, portrait, margin=0.5in]{geometry}
\usepackage{hyperref}
\usepackage{float}
\title{EE416 Final Project:\\Generalized Linear Models for Neural Data}
\date{\today}
\author{Kyle Gagner and Fred Davis}
\begin{document}
\maketitle

\begin{abstract}

We developed methods to simulate neural spiking using a generalized linear model (GLM). We also compared fitted model
parameters to ground truth - parameters which were used in the simulation. Then, we tested the resilience of the fitter
against various parameters, and found it to have generally good error performance, with the exception of parameters
which the fitter was not given enough data to estimate. Next, we used the fitter to estimate the model parameters of
real neurons (as opposed to simulated ones) and used the model to explain the behavior of the neuron. Lastly, we
analyzed the inter-spike intervals of a neuron simulated using a renewal process. We were able to roughly fit the
distribution of inter-spike intervals to a gamma distribution.

\end{abstract}

\section{Summary of Results}

\subsection{Simulating a GLM}

A GLM is a mostly linear model with a non-linear element. The parameters in our model are filter coefficients in the
linear portion of the model. There is a stimulus filter, which determines the system input's contribution, a self
interaction filter which determine's the system output's contribution, and a constant offset. The first task was to
select model parameters and simulate the system.

We used stimulus filter $f[t]=20e^{-t}$, self interaction filter $h[t]=-200e^{-t}$, and offset $b=-15$ as the
parameters to our GLM simulation. Filters were 15 coefficients long. The input stimulus was:

$$s(t)\sim
\begin{cases}
0 & t < 2000\\
\mathcal{N}(\mu=0.3, \sigma=0.1) & 2000 \leq t < 20000
\end{cases}$$

\begin{figure}[H]
\includegraphics[width=\textwidth]{section_4_fig1.pdf}
\caption{Simulation of a GLM}
\label{fig41}
\end{figure}

The filter coefficients (True series) and stimulus are ploted in Figure \ref{fig41} along with the spiking
response of the simulation. Here it can be seen that spiking does not occur when the stimulus is zero because the
relatively large negative offset dominates. When the stimulus is noisy, spiking occurs. The spiking appears
qualitatively plausible.

\subsection{Fitting Parameters to a GLM}

A model was then fit to the simulated data. The coefficients and their standard error (Estimated series) are shown
overlaid on the ground truth in Figure \ref{fig41}. The fit for the stimulus filter is good. The fit for the
self interaction filter is extremely poor for the first few coefficients and quickly improved for subsequent
coefficients. This can be explained by the fact that the optimization code depends on
observations of various interarrival times in order to estimate these coefficients. Due to the model's refractory
period, there are no or few observations for short interarrivals. By contrast, any spike in the response is a useful
observation for optimizing any of the stimulus filter coefficients, which is why their fits are more consistently good.

The fitter works properly but where it is not given enough information to function, the results are not useful. Given
this limitation, it makes sense to simply exclude coefficients with excessive standard error from error estimates. The
method used for this is discussed in more detail in the Analysis section.

\subsection{Understanding GLM Performance}

The same simulation and fitting methods were repeated with varying parameters to explore performance of the fitter.
The results represent two sets of data. One where the number of samples in the stimulus signal were varied and a
second where the offset $b$ was varied. Absolute error is shown for the offset parameter, and both RMSE (root mean
squared error) and MSE (mean standard error) error metrics.

\begin{figure}[H]
\includegraphics[width=\textwidth]{section_4_fig2.pdf}
\caption{Simulation of a GLM and parameters fitted to the simulated data}
\label{fig42}
\end{figure}

The datasets are plotted in Figure \ref{fig42}. In general, there is no observable correlation between offset parameter
error and the independent variable in either dataset. There is a clear downward trend in stimulus filter MSE in both
datasets, but RMSE for the stimulus filter only has a clear downward trend as the number of samples increases,
suggesting that the total number of observations is more significant than the number of spikes for fitting the stimulus
filter. By contrast, slight downward trends in RMSE of the self interaction filter are observable in both datasets,
suggesting that the number of spikes observed is more significant than total number of samples in fitting the self
interaction filters. Another interesting feature of the plots is that self interaction filter fits tend to be better,
suggesting that the stimulus filter is harder to fit.

\subsection{GLM Fits of Neural Data}

A GLM model was fitted to Allen Institute data recorded from live neurons. The models simplify the dynamics of the
neural systems enough to draw useful conclusions from the data, while providing enough degrees of freedom to be useful.

\begin{figure}[H]
\includegraphics[width=\textwidth]{section_5_fig1.pdf}
\caption{Simulation of a GLM and parameters fitted to the simulated data}
\label{fig51}
\end{figure}

The plots in Figure \ref{fig51} show the stimulus filter, self interaction filter, and offset coefficients and their
standard errors for the Allen Institute datasets. Some features are expected from the results already analyzed in the
previous section. The self interaction filters begin at relatively large negative values, indicating a refractory
period which is expected. The fits for the first few coefficients of the self interaction filters also have large
error, which is also expected when the refractory period prevents the fitter from observing data with very small
interarrival times between spikes. The stimulus filters are also interesting to observe, but say relatively little
about the dynamics of the systems compared to the self interaction filters. Behavior is largely dependent on the
stimulus through these stimulus filters.

\subsection{Inter-Spike Interval Analysis}

The inter-spike intervals were calculated by taking the difference between adjacent spike times provided in
ISIsimulated.txt. The provided spike times had been generated via a renewal process. The correlation between
successive inter-spike intervals is 0.0244.

\begin{figure}[H]
\includegraphics[width=\textwidth]{section_6_fig1.pdf}
\caption{The inter-spike intervals from ISIsimulated.txt}
\label{fig61}
\end{figure}

A histogram of the distribution of the inter-spike intervals is shown in Figure \ref{fig61}. The mean and variance of
the distribution are estimated to be 2.52 and 2.55 respectively. Overlayed is the probability density function of a
gamma distribution to model the distribution distribution of the inter-spike intervals. It has a goodness of fit of
0.938.

\section{Analysis}

The code for GLM simulation, GLM fitting, and data analysis and plotting was written in Python making extensive use
of packages as mentioned in references. Nontrivial parts of this code are documented in this section.

\subsection{Simulation of a GLM}

The simulation function takes a stimulus $s$, stimulus filter $f$, self interaction filter $h$, and offset $b$. Note
that the stimulus and self interaction filters are a series of coefficients each assumed to begin at time $t=1$, not
$t=0$. Time $t$ is taken to be discrete. First an intermediate result $x[t]$ is computed, which is then used to
calculate $n[t]$, the spiking history, using a Poisson distribution $\mathcal{P}(\lambda)$.

$$x[t]=s[t]*f[t]$$
$$n[t]\sim
\begin{cases}
0 & t < 0\\
\mathcal{P}(exp(x[t]+n[\tau-t]*h[\tau]+b)) & t \geq 0
\end{cases}$$

In practical terms, $n[t]$ is zero padded to the left to sufficient negative time to make calculating the expression
easy without running off the beginning of the array when convolving with $h[t]$. Each value of $n[t]$ from $t=0$ on
can be calculated only after the previous value is known, due to the convolution. The simulation routine returns
$n[t] \forall 0 \leq t < len(s[t])$.

\subsection{Fitting Parameters to a GLM}

Fitting GLM parameters was accomplished using the \textit{statsmodels.api.GLM} function in
Python using \\\textit{statsmodels.api.families.Poisson()} for the family parameter. Two
matrices, one of exogenous variables and one of endogenous variables are passed to the fitting routine. Using the
stimulus $s[t]$ and spike response $n[t]$ of length $l$, and filter length $d$, the matrices are constructed as
follows:

$$Exog=
\begin{bmatrix}
n[d-1] & n[d-2] & \hdots & n[0] & s[d-1] & s[d-2] & \hdots & s[0] & 1\\
n[d] & n[d-1] & \hdots & n[1] & s[d] & s[d-1] & \hdots & s[1] & 1\\
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
n[l-2] & n[l-3] & \hdots & n[l-d-1] & s[l-2] & s[l-3] & \hdots & s[l-d-1] & 1
\end{bmatrix}$$

$$Endog=
\begin{bmatrix}
n[d] \\
n[d+1] \\
\vdots \\
n[l-1]
\end{bmatrix}$$

The result returned contains the parameters of interest packed into a vector:

$$\begin{bmatrix}
h[0] & h[1] & \hdots & h[d-1] & f[0] & f[1] & \hdots & f[d-1] & b
\end{bmatrix}$$

Another vector with the same layout contains estimates of the standard errors of each of these parameters.

\subsection{Understanding GLM Performance}

To plot GLM performance, the existing methods for simulating and fitting neural data were used, using stimulus with
the same normal distribution and the same filters. Two datasets were generated, one by varying the length of the
stimulus, and a second by varying the offset parameter. Error metrics were plotted against stimulus length and spike
count in the first dataset. Error metrics were plotted against spike count in the second dataset. Three error metrics
were used, a simple absolute error for the offset parameter, a modified root mean squared error (RMSE) for the filters,
and a modified mean standard error (MSE) for the filters. The modification in each case was to discard coefficients
with a standard error estimate greater than 100.

\subsection{GLM Fits of Neural Data}

In previous sections, the GLM fitting was performed against simulated data. In this section, models were fit to real
datasets. No analysis tools besides those developed in the previous section were required.

\subsection{Inter-Spike Interval Analysis}

The inter-spike intervals were calculated by taking the difference between the spike times that were loaded from
ISIsimulated.txt. Then, the correlation between successive intervals was taken with NumPy's \textit{corrcoef} function.
The correlation was nearly zero, which makes sense because the spike times were generated using a renewal process,
so the intervals should be independent of each other. Then, the histogram was plotted using Matplotlib's \textit{histogram}
function. Looking at the histogram, it appeared to roughly follow a gamma distribution. SciPy's \textit{stats.gamma.fit function}
was used to fit the histogram to a gamma distribution, which was then overlayed on the histogram. Lastly, the
goodness of fit was measured using a Kolmogorov-Smirnov test.

\section{References}

\begin{itemize}
\item \textbf{NumPy:} \url{https://www.numpy.org/}
\item \textbf{Matplotlib:} \url{https://matplotlib.org/}
\item \textbf{StatsModels:} \url{https://www.statsmodels.org/}
\item \textbf{SciPy:} \url{https://www.scipy.org/}
\end{itemize}

\section{Appendices}

Code for this project is appended as a separate zip file \textbf{DavisGagnerFinalProject.zip} containing:

\begin{itemize}
\item \textbf{report.pdf} this report
\item \textbf{sim\_GLM.py} Python code for simulating a GLM
\item \textbf{fit\_GLM.py} Python code for fitting GLM parameters to a dataset
\item \textbf{section4.py} Python code for GLM simulation and fitting experiments and plots
\item \textbf{section5.py} Python code for GLM fits to neural data and plots
\item \textbf{section6.py} Python code for interarrival time analysis and plots
\item \textbf{binned\_spikes\_cell\_1.txt} spike data for cell 1
\item \textbf{binned\_stim\_cell\_1.txt} stimulus data for cell 1
\item \textbf{binned\_spikes\_cell\_2.txt} spike data for cell 2
\item \textbf{binned\_stim\_cell\_2.txt} stimulus data for cell 2
\item \textbf{ISIsimulated.txt} interarrival time data
\end{itemize}

\end{document}
